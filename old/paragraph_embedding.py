import gensim
from gensim.models import Doc2Vec
from nltk.tokenize import RegexpTokenizer
import numpy as np
from old.classifier import svc, xgboost
from sklearn.model_selection import train_test_split
from helpers.utils import load_dataset

def doc2vec_embed(both_models=True, save_models=False):
    file_name = 'reports_apkinfo.manifest_droidmon'
    # file_name = 'reports_apkinfo.manifest_droidmon'
    reports, labels = load_dataset(file_name=file_name)

    tokenizer = RegexpTokenizer(r'\w+')
    tag_doc = gensim.models.doc2vec.TaggedDocument

    all_content_train = [tag_doc(tokenizer.tokenize(report), [i]) for i, report in enumerate(reports)]

    # dm=0 - used model is distributed bag of words (DBOW)
    d2v_model_dbow = Doc2Vec(all_content_train, vector_size=1000, window=10, min_count=50, workers=7, dm=0, alpha=0.025,
                        min_alpha=0.001)

    d2v_model_dbow.train(all_content_train, total_examples=d2v_model_dbow.corpus_count, epochs=40, start_alpha=0.025,
                    end_alpha=-0.00025)
    #d2v_model.save("d2v.model")
    #d2v_model.load("d2v.model")

    vectors_dbow = d2v_model_dbow.docvecs.vectors_docs

    if both_models:
        d2v_model_dm = Doc2Vec(all_content_train, vector_size=1000, window=10, min_count=10, workers=7, dm=1, alpha=0.025,
                                 min_alpha=0.001)

        d2v_model_dm.train(all_content_train, total_examples=d2v_model_dm.corpus_count, epochs=40, start_alpha=0.025,
                             end_alpha=-0.00025)
        vectors_dm = d2v_model_dm.docvecs.vectors_docs

        vectors = np.concatenate((vectors_dm, vectors_dbow), axis=1)
        print(d2v_model_dm.docvecs.vectors_docs.shape)
        train_vectors_dm, test_vectors_dm, _, _ = train_test_split(vectors_dm, labels,
                                                                                        test_size=0.165,
                                                                                        random_state=42)
    print(d2v_model_dbow.docvecs.vectors_docs.shape)



    train_vectors_dbow, test_vectors_dbow, train_labels, test_labels = train_test_split(vectors_dbow, labels,
                                                                              test_size=0.165,
                                                                              random_state=42)

    train_vectors_dbow = np.array(train_vectors_dbow)
    test_vectors_dbow = np.array(test_vectors_dbow)

    print('dbow')
    svc(train_vectors_dbow, test_vectors_dbow, train_labels, test_labels)
    xgboost(train_vectors_dbow, test_vectors_dbow, train_labels, test_labels)

    if both_models:
        train_vectors, test_vectors, _, _ = train_test_split(vectors, labels,
                                                                              test_size=0.165,
                                                                              random_state=42)
        train_vectors_dm = np.array(train_vectors_dm)
        test_vectors_dm = np.array(test_vectors_dm)

        train_vectors = np.array(train_vectors)
        test_vectors = np.array(test_vectors)

        print('dm')
        svc(train_vectors_dm, test_vectors_dm, train_labels, test_labels)
        xgboost(train_vectors_dm, test_vectors_dm, train_labels, test_labels)

        print('all')
        svc(train_vectors, test_vectors, train_labels, test_labels)
        xgboost(train_vectors, test_vectors, train_labels, test_labels)

    if save_models:
        print('saving models')
        d2v_model_dbow.save("d2v_models/d2v_dbow.model")
        d2v_model_dm.save('d2v_models/d2v_dm.model')


doc2vec_embed(both_models=False, save_models=False)
