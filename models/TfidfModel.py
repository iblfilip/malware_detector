import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.feature_extraction.text import TfidfTransformer
from helpers.utils import save, load
import logging

logger = logging.getLogger(__name__)


class TfidfModel:
    """
    TF-IDF model class
    """
    def __init__(self, config):
        """
        Init TF-IDF models, load saved models from local path if do_training = False
        :param config: configuration object
        """
        self.config = config
        self.model_path = self.config.get('output_dir') + self.config.get('model_name')
        if self.config.get('do_training'):
            logger.info('Initializing Tf-Idf embedding with config')
            self.config.print()
            self.count_vectorizer = CountVectorizer(ngram_range=(1,3))
            self.selector = SelectKBest(score_func=chi2, k=self.config.get('k_best_features'))
            self.tfidf_transformer = TfidfTransformer(smooth_idf=self.config.get('smooth_idf'), use_idf=self.config.get('use_idf'))
        else:
            logger.info('Skipping TF-IDF training phase')
            self.count_vectorizer = load(self.model_path + '.vectorizer')
            self.selector = load(self.model_path + '.selector')
            self.tfidf_transformer = load(self.model_path + '.transformer')

    def train(self, train_reports, train_labels, save_model=False):
        """
        Training TF-IDF model on training dataset, using Chi-Square test to control the dimensionality of vocabulary
        :param train_reports: train reports dataset
        :param train_labels: list of labels for train reports dataset
        :param save_model: mark whether save model after training
        """
        logger.info('Learning Tf-Idf embedding on training dataset')
        self.count_vectorizer.fit(train_reports)
        vectors_train = self.count_vectorizer.transform(train_reports)
        vectors_train = vectors_train.toarray()

        self.selector.fit(vectors_train, train_labels)
        best_vectors_train = self.selector.transform(vectors_train)

        self.tfidf_transformer.fit(best_vectors_train)

        if save_model:
            save(self.model_path + '.vectorizer', self.count_vectorizer)
            save(self.model_path + '.selector', self.selector)
            save(self.model_path + '.transformer', self.tfidf_transformer)

    def transform(self, reports):
        """
        Conduct TF-IDF vectorization on reports dataset
        :param reports: dataset of reports
        :return: dense vector representation of reports dataset
        """
        logger.info('Encoding dataset')

        vectors = self.count_vectorizer.transform(reports)
        vectors = vectors.toarray()
        best_vectors = self.selector.transform(vectors)
        tfidf_vectors = self.tfidf_transformer.transform(best_vectors)

        tfidf_densed = tfidf_vectors.todense()
        vectors_densed = np.array(tfidf_densed)
        return vectors_densed
