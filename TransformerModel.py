from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup, \
    AlbertTokenizer, AlbertForSequenceClassification, RobertaForSequenceClassification, RobertaTokenizer, \
    DistilBertForSequenceClassification, DistilBertTokenizer, FlaubertForSequenceClassification, FlaubertTokenizer
import torch
import time
import os
import numpy as np
import random
from keras.preprocessing.sequence import pad_sequences
from torch.utils.data import TensorDataset, DataLoader, RandomSampler
from helpers.utils import format_time, print_model_layers
from scipy.special import softmax
from helpers.evaluation import compute_majority_voting, compute_pooling, print_results
from helpers.plots import show_report_length, show_tokens_length, plot_loss
import logging

logger = logging.getLogger(__name__)


class TransformerModel:
    def __init__(self, config):
        self.config = config
        self.model_path = self.config.get('output_dir') + self.config.get('model_name')
        self.model = None
        self.tokenizer = None
        self.chunk_size_with_special_tokens = self.config.get('chunk_size') + 2
        self.is_cuda_available = torch.cuda.is_available()
        self.device = None

        if self.config.get('do_training'):
            logger.info('Initializing Transformer model with config')
            self.config.print()
            self.load_model_tokenizer(from_local=False)
        else:
            logger.info('Loading Transformer from ' + self.model_path)
            self.load_model_tokenizer(from_local=True)

        if self.is_cuda_available:
            self.device = torch.device('cuda')

    # def batch_and_tokenize_reports_old(reports, labels, max_tokens_threshold=20000, chunk_size=500, stride=0):
    #     input_ids = []
    #     input_labels = []
    #     input_length = []
    #     # to keep evidence about which chunk belongs to which report
    #     input_report_ids = []
    #
    #     for i_report, (report, label) in enumerate(zip(reports, labels)):
    #         tokenized_report = tokenizer.tokenize(report[:100000])
    #         print('batching report {}, len {}'.format(i_report, len(tokenized_report)))
    #         input_length.append(len(tokenized_report))
    #
    #         batches = []
    #         token_iter = 0
    #         i = 0
    #         token_seq = []
    #         while i < len(tokenized_report[:max_tokens_threshold]):
    #             token = tokenized_report[i]
    #             token_seq.append(token)
    #
    #             if token_iter == chunk_size or i == len(tokenized_report) - 1:
    #                 batches.append(token_seq)
    #                 token_seq = []
    #                 token_iter = 0
    #                 if i != len(tokenized_report) - 1:
    #                     if i < stride:
    #                         i = 0
    #                     else:
    #                         i -= stride
    #
    #             token_iter += 1
    #             i += 1
    #
    #         for batch in batches:
    #             encoded_sent = tokenizer.encode(
    #                 batch,
    #                 add_special_tokens=True
    #             )
    #             input_ids.append(encoded_sent)
    #             input_labels.append(label)
    #             input_report_ids.append(i_report)
    #
    #     return input_ids, input_labels, input_length, input_report_ids

    def batch_reports(self, reports, labels):
        input_ids = []
        input_labels = []
        input_length = []
        # to keep evidence about which chunk belongs to which report
        input_report_ids = []

        for i_report, (report, label) in enumerate(zip(reports, labels)):
            # input_length.append(len(tokenized_report))

            batches = []

            for attr in report:
                if report[attr] is '':
                    continue

                tokenized_attr = self.tokenizer.tokenize(report[attr][:15000])
                token_iter = 0
                i = 0
                token_seq = []

                while i < len(tokenized_attr[:self.config.get('tokens_threshold')]):
                    token = tokenized_attr[i]
                    # for i, token in enumerate(tokenized_report[:max_tokens_threshold]):
                    token_seq.append(token)

                    if token_iter == self.config.get('chunk_size') or i == len(tokenized_attr) - 1:
                        batches.append(token_seq)
                        token_seq = []
                        token_iter = 0
                        if i != len(tokenized_attr) - 1:
                            if i < self.config.get('stride'):
                                i = 0
                            else:
                                i -= self.config.get('stride')

                    token_iter += 1
                    i += 1

            for batch in batches:
                encoded_sent = self.tokenizer.encode(
                    batch,
                    add_special_tokens=True
                )
                input_ids.append(encoded_sent)
                input_labels.append(label)
                input_report_ids.append(i_report)

            if i_report % 10 == 0:
                logger.info('batched report {}, batch len {}'.format(i_report, len(batches)))

        return input_ids, input_labels, input_length, input_report_ids

    @staticmethod
    def create_attention_mask(input_ids):
        attention_masks = []
        for report in input_ids:
            att_mask = [int(token_id > 0) for token_id in report]
            attention_masks.append(att_mask)
        return attention_masks

    def save(self, args=None):
        # if not os.path.exists(output_dir):
        #     os.makedirs(output_dir)

        logger.info('Save model to {}'.format(self.model_path))

        # if not os.path.exists(output_dir):
        #     os.makedirs(output_dir)

        model_to_save = self.model.module if hasattr(self.model, 'module') else self.model
        model_to_save.save_pretrained(self.model_path)
        self.tokenizer.save_pretrained(self.model_path)

        # save training arguments
        if args:
            torch.save(args, os.path.join(self.model_path, 'training_args.bin'))

    def pick_tokenizer_model(self):
        if self.config.get('model') == 'bert':
            tokenizer = BertTokenizer
            model = BertForSequenceClassification
            model_name = 'bert-base-uncased'
        elif self.config.get('model') == 'albert':
            tokenizer = AlbertTokenizer
            model = AlbertForSequenceClassification
            model_name = 'albert-base-v2'
        elif self.config.get('model') == 'roberta':
            tokenizer = RobertaTokenizer
            model = RobertaForSequenceClassification
            model_name = 'roberta-base'
        elif self.config.get('model') == 'distilbert':
            tokenizer = DistilBertTokenizer
            model = DistilBertForSequenceClassification
            model_name = 'distilbert-base-uncased'
        elif self.config.get('model') == 'flaubert':
            tokenizer = FlaubertTokenizer
            model = FlaubertForSequenceClassification
            model_name = 'flaubert/flaubert_base_cased'
        return tokenizer, model, model_name

    def load_model_tokenizer(self, from_local=False):
        tokenizer, model, model_name = self.pick_tokenizer_model()
        if from_local:
            self.tokenizer = tokenizer.from_pretrained(self.model_path, do_lower_case=True)
            self.model = model.from_pretrained(
                self.model_path,
                num_labels=2,
                output_attentions=False,
                output_hidden_states=False
            )
        else:
            self.tokenizer = tokenizer.from_pretrained(model_name, do_lower_case=True)
            self.model = model.from_pretrained(
                model_name,
                num_labels=2,
                output_attentions=False,
                output_hidden_states=False
            )

    def train(self, train_reports, train_labels, validation_reports, validation_labels, save_model=False):
        train_input_ids, train_input_labels, train_input_length, _ = self.batch_reports(train_reports, train_labels)
        train_inputs = pad_sequences(train_input_ids, maxlen=self.config.get('chunk_size_with_special_tokens'),
                                     dtype='long',
                                     value=0, truncating='post', padding='post')
        train_masks = TransformerModel.create_attention_mask(train_inputs)

        validation_input_ids, validation_input_labels, validation_input_length, validation_report_ids = self.batch_reports(
            validation_reports, validation_labels)
        validation_inputs = pad_sequences(validation_input_ids,
                                          maxlen=self.config.get('chunk_size_with_special_tokens'),
                                          dtype='long',
                                          value=0, truncating='post', padding='post')
        validation_masks = TransformerModel.create_attention_mask(validation_inputs)

        # show_tokens_length(train_input_length, self.config.get('tokens_threshold'))

        train_inputs = torch.tensor(train_inputs)
        train_input_labels = torch.tensor(train_input_labels)
        train_masks = torch.tensor(train_masks)

        validation_inputs = torch.tensor(validation_inputs)
        validation_input_labels = torch.tensor(validation_input_labels)
        validation_masks = torch.tensor(validation_masks)
        validation_report_ids = torch.tensor(validation_report_ids)

        # create dataloader for training set
        train_data = TensorDataset(train_inputs, train_masks, train_input_labels)
        train_sampler = RandomSampler(train_data)
        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=self.config.get('batch_size'))

        # create dataloader for validation set
        validation_data = TensorDataset(validation_inputs, validation_masks, validation_input_labels,
                                        validation_report_ids)
        validation_sampler = RandomSampler(validation_data)
        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler,
                                           batch_size=self.config.get('batch_size'))

        if self.is_cuda_available:
            self.model.cuda()

        print_model_layers(self.model.named_parameters())

        optimizer = AdamW(self.model.parameters(),
                          lr=self.config.get('learning_rate'),
                          eps=self.config.get('eps'))

        epochs = self.config.get('n_epochs')
        total_steps = len(train_dataloader) * epochs

        scheduler = get_linear_schedule_with_warmup(optimizer,
                                                    num_warmup_steps=0,
                                                    num_training_steps=total_steps)

        # training

        # to make it reproducible
        seed_val = self.config.get('random_value')
        random.seed(seed_val)
        np.random.seed(seed_val)
        torch.manual_seed(seed_val)
        torch.cuda.manual_seed_all(seed_val)

        loss_values = []

        for epoch_i in range(0, epochs):
            logger.info('---- Epoch: {} / {} ----'.format(epoch_i + 1, epochs))
            logger.info('training')

            t0 = time.time()

            # reset total loss for epoch
            total_loss = 0

            # put model into training mode
            self.model.train()

            for step, batch in enumerate(train_dataloader):
                if step % 100 == 0 and not step == 0:
                    elapsed = format_time(time.time() - t0)

                    logger.info('Batch {:>5,} of {:>5,}. Elapsed {:}'.format(step, len(train_dataloader), elapsed))

                # unpack training batch from dataloader
                b_input_ids = batch[0].to(self.device)
                b_input_mask = batch[1].to(self.device)
                b_labels = batch[2].to(self.device)

                self.model.zero_grad()

                if self.config.get('model') == 'bert':
                    outputs = self.model(b_input_ids,
                                         token_type_ids=None,
                                         attention_mask=b_input_mask,
                                         labels=b_labels)
                else:
                    outputs = self.model(b_input_ids,
                                         attention_mask=b_input_mask,
                                         labels=b_labels)

                loss = outputs[0]

                total_loss += loss.item()

                # backward pass to calculate gradients
                loss.backward()

                # clip gradients to 1.0, help prevent exploding gradients
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)

                optimizer.step()
                scheduler.step()

            # calculate average loss over training data
            avg_train_loss = total_loss / len(train_dataloader)
            loss_values.append(avg_train_loss)

            logger.info(' Average  training  loss: {0:2f}'.format(avg_train_loss))
            logger.info(' Training epoch took {:}'.format(format_time(time.time() - t0)))

            # validation
            logger.info('Running validation')

            t0 = time.time()

            self.model.eval()

            validation_preds = []
            validation_true_labels = []
            validation_report_ids = []

            for batch in validation_dataloader:
                batch = tuple(t.to(self.device) for t in batch)

                b_input_ids, b_input_mask, b_labels, b_report_ids = batch

                with torch.no_grad():
                    if self.config.get('model') == 'bert':
                        outputs = self.model(b_input_ids,
                                             token_type_ids=None,
                                             attention_mask=b_input_mask)
                    else:
                        outputs = self.model(b_input_ids,
                                             attention_mask=b_input_mask)

                logits = outputs[0]
                logits = logits.detach().cpu().numpy()
                label_ids = b_labels.to('cpu').numpy()
                batch_report_ids = b_report_ids.to('cpu').numpy()

                predics = softmax(logits)
                validation_preds.append(predics)
                validation_report_ids.append(batch_report_ids)
                validation_true_labels.append(label_ids)

            validation_preds = np.concatenate(validation_preds, axis=0)
            validation_report_ids = np.concatenate(validation_report_ids, axis=0)
            validation_true_labels = np.concatenate(validation_true_labels, axis=0)

            pred_labels = np.argmax(validation_preds, axis=1)

            majority_predictions = compute_majority_voting(validation_report_ids, pred_labels)
            mean_predictions = compute_pooling(validation_report_ids, validation_preds)

            logger.info('   Majority scoring on validation dataset')
            print_results(majority_predictions, validation_labels)
            logger.info('   Mean scoring on validation dataset')
            print_results(mean_predictions, validation_labels)
            logger.info('   Just scoring on validation dataset')
            print_results(pred_labels, validation_true_labels)

            logger.info('Validation took: {:}'.format(format_time(time.time() - t0)))

        logger.info('')
        logger.info('Training completed')

        plot_loss(loss_values)

        if save_model:
            self.save()

    def predict(self, test_reports, test_labels):
        test_input_ids, test_input_labels, test_input_length, test_report_ids = self.batch_reports(test_reports,
                                                                                                   test_labels)
        test_inputs = pad_sequences(test_input_ids, maxlen=self.config.get('chunk_size_with_special_tokens'),
                                    dtype='long',
                                    value=0, truncating='post', padding='post')
        test_masks = TransformerModel.create_attention_mask(test_inputs)

        test_inputs = torch.tensor(test_inputs)
        test_input_labels = torch.tensor(test_input_labels)
        test_masks = torch.tensor(test_masks)

        test_report_ids = torch.tensor(test_report_ids)

        # create dataloader for test set
        test_data = TensorDataset(test_inputs, test_masks, test_input_labels, test_report_ids)
        test_sampler = RandomSampler(test_data)
        test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=self.config.get('batch_size'))

        if self.is_cuda_available:
            self.model.cuda()

        logger.info('Predicting labels for {:,} test reports...'.format(len(test_inputs)))

        self.model.eval()

        test_preds, true_labels, report_ids = [], [], []

        t0 = time.time()

        for (step, batch) in enumerate(test_dataloader):
            if self.is_cuda_available:
                batch = tuple(t.to(self.device) for t in batch)
            else:
                batch = tuple(t for t in batch)

            if step % 100 == 0 and not step == 0:
                elapsed = format_time(time.time() - t0)

                logger.info('Batch {:>5,} of {:>5,}. Elapsed {:}'.format(step, len(test_dataloader), elapsed))

            b_input_ids, b_input_mask, b_labels, b_report_ids = batch

            with torch.no_grad():
                if self.config.get('model') == 'bert':
                    outputs = self.model(b_input_ids,
                                         token_type_ids=None,
                                         attention_mask=b_input_mask)
                else:
                    outputs = self.model(b_input_ids,
                                         attention_mask=b_input_mask)

            logits = outputs[0]

            logits = logits.detach().cpu().numpy()
            label_ids = b_labels.to('cpu').numpy()
            batch_report_ids = b_report_ids.to('cpu').numpy()

            batch_preds = softmax(logits)

            test_preds.append(batch_preds)
            true_labels.append(label_ids)
            report_ids.append(batch_report_ids)

        logger.info('Done')

        # combine predictions across batches
        test_preds = np.concatenate(test_preds, axis=0)
        true_labels = np.concatenate(true_labels, axis=0)
        report_ids = np.concatenate(report_ids, axis=0)

        pred_labels = np.argmax(test_preds, axis=1)

        majority_predictions = compute_majority_voting(report_ids, pred_labels)
        mean_predictions = compute_pooling(report_ids, test_preds)

        # with majority voting
        logger.info('   Majority scoring on test dataset')
        print_results(majority_predictions, test_labels)

        # mean prediction
        logger.info('   Mean scoring on test dataset')
        print_results(mean_predictions, test_labels)

        # just predictions
        logger.info('   Just predics scoring on test dataset')
        print_results(pred_labels, true_labels)

# def run(self, conf, train_reports, train_labels, validation_reports, validation_labels, test_reports, test_labels):
#
#     #def preprocess():
#     #cleaned_reports, labels = load_dataset(conf.get('dataset'))
#     # show_report_length(cleaned_reports, labels)
#
#
#     input_ids = []
#     input_labels = []
#     input_length = []
#
#     model_name = conf.get('model')
#     model_path = conf.get('model_path')
#     max_tokens_threshold = conf.get('tokens_threshold')
#     chunk_size = conf.get('chunk_size')
#     stride = conf.get('stride')
#     do_train = conf.get('do_training')
#
#     # reccomended by authors either 16 or 32
#     batch_size = conf.get('batch_size')
#
#     # batch, pad sequences and masks
#     if do_train:
#         train_input_ids, train_input_labels, train_input_length, _ = batch_and_tokenize_reports(train_reports, train_labels)
#         train_inputs = pad_sequences(train_input_ids, maxlen=self.config.get('chunk_size_with_special_tokens'), dtype='long',
#                                      value=0, truncating='post', padding='post')
#         train_masks = create_attention_mask(train_inputs)
#
#         validation_input_ids, validation_input_labels, validation_input_length, _ = batch_and_tokenize_reports(validation_reports, validation_labels)
#         validation_inputs = pad_sequences(validation_input_ids, maxlen=self.config.get('chunk_size_with_special_tokens'), dtype='long',
#                                           value=0, truncating='post', padding='post')
#         validation_masks = create_attention_mask(validation_inputs)
#
#         show_tokens_length(train_input_length, max_tokens_threshold)
#
#
#     test_input_ids, test_input_labels, test_input_length, test_report_ids = batch_and_tokenize_reports(test_reports, test_labels)
#     test_inputs = pad_sequences(test_input_ids, maxlen=self.config.get('chunk_size_with_special_tokens'), dtype='long',
#                               value=0, truncating='post', padding='post')
#     test_masks = create_attention_mask(test_inputs)
#
#     # convert to pytorch
#
#     if do_train:
#         train_inputs = torch.tensor(train_inputs)
#         train_input_labels = torch.tensor(train_input_labels)
#         train_masks = torch.tensor(train_masks)
#
#         validation_inputs = torch.tensor(validation_inputs)
#         validation_input_labels = torch.tensor(validation_input_labels)
#         validation_masks = torch.tensor(validation_masks)
#
#     test_inputs = torch.tensor(test_inputs)
#     test_input_labels = torch.tensor(test_input_labels)
#     test_masks = torch.tensor(test_masks)
#
#     test_report_ids = torch.tensor(test_report_ids)
#
#
#     if do_train:
#         # create dataloader for training set
#         train_data = TensorDataset(train_inputs, train_masks, train_input_labels)
#         train_sampler = RandomSampler(train_data)
#         train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)
#
#         # create dataloader for validation set
#         validation_data = TensorDataset(validation_inputs, validation_masks, validation_input_labels)
#         validation_sampler = RandomSampler(validation_data)
#         validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)
#
#     # create dataloader for test set
#     test_data = TensorDataset(test_inputs, test_masks, test_input_labels, test_report_ids)
#     test_sampler = RandomSampler(test_data)
#     test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)
#
#     if is_cuda_available:
#         model.cuda()
#
#     params = list(model.named_parameters())
#     print('Bert has {} different named params'.format(len(params)))
#
#     print('--- Embedding layer ---')
#     for p in params[0:5]:
#         print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))
#
#     print('--- First transformer --- ')
#     for p in params[5:21]:
#         print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))
#
#     print('--- Output layer --- ')
#     for p in params[-4:]:
#         print('{:<55} {:>12}'.format(p[0], str(tuple(p[1].size()))))
#
#
#     if do_train:
#         # optimizer and learning rate scheduler
#         # authors reccomend choosing
#         # lr = 5e-5, 3e-5, 2e-5
#         # n of epochs 2, 3, 4
#         # epsilon eps -
#         optimizer = AdamW(model.parameters(),
#                           lr=conf.get('learning_rate'),
#                           eps=conf.get('eps'))
#
#         epochs = conf.get('epochs')
#         total_steps = len(train_dataloader) * epochs
#
#         scheduler = get_linear_schedule_with_warmup(optimizer,
#                                                     num_warmup_steps=0,
#                                                     num_training_steps=total_steps)
#
#         # training
#
#         # to make it reproducible
#         seed_val = conf.get('random_value')
#         random.seed(seed_val)
#         np.random.seed(seed_val)
#         torch.manual_seed(seed_val)
#         torch.cuda.manual_seed_all(seed_val)
#
#         loss_values = []
#
#         for epoch_i in range(0, epochs):
#             print('')
#             print('---- Epoch: {} / {} ----'.format(epoch_i + 1, epochs))
#             print('training')
#
#             t0 = time.time()
#
#             # reset total loss for epoch
#             total_loss = 0
#
#             # put model into training mode
#             model.train()
#
#             for step, batch in enumerate(train_dataloader):
#                 if step % 100 == 0 and not step == 0:
#                     elapsed = format_time(time.time() - t0)
#
#                     print('Batch {:>5,} of {:>5,}. Elapsed {:}'.format(step, len(train_dataloader), elapsed))
#
#                 # unpack training batch from dataloader
#                 b_input_ids = batch[0].to(device)
#                 b_input_mask = batch[1].to(device)
#                 b_labels = batch[2].to(device)
#
#                 model.zero_grad()
#
#                 if model_name == 'bert':
#                     outputs = model(b_input_ids,
#                                     token_type_ids=None,
#                                     attention_mask=b_input_mask,
#                                     labels=b_labels)
#                 else:
#                     outputs = model(b_input_ids,
#                                     attention_mask=b_input_mask,
#                                     labels=b_labels)
#
#                 loss = outputs[0]
#
#                 total_loss += loss.item()
#
#                 # backward pass to calculate gradients
#                 loss.backward()
#
#                 # clip gradients to 1.0, help prevent exploding gradients
#                 torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
#
#                 optimizer.step()
#                 scheduler.step()
#
#             # calculate average loss over training data
#             avg_train_loss = total_loss/len(train_dataloader)
#             loss_values.append(avg_train_loss)
#
#             print('')
#             print(' Average  training  loss: {0:2f}'.format(avg_train_loss))
#             print(' Training epoch took {:}'.format(format_time(time.time() - t0)))
#
#
#             # validation
#             print('')
#             print('Running validation')
#
#
#             t0 = time.time()
#
#             model.eval()
#
#             eval_loss, eval_accuracy = 0, 0
#             nb_eval_steps, np_eval_examples = 0, 0
#
#             for batch in validation_dataloader:
#                 batch = tuple(t.to(device) for t in batch)
#
#                 b_input_ids, b_input_mask, b_labels = batch
#
#                 with torch.no_grad():
#                     if model_name == 'bert':
#                         outputs = model(b_input_ids,
#                                         token_type_ids=None,
#                                         attention_mask=b_input_mask)
#                     else:
#                         outputs = model(b_input_ids,
#                                         attention_mask=b_input_mask)
#
#                 logits = outputs[0]
#                 logits = logits.detach().cpu().numpy()
#                 label_ids = b_labels.to('cpu').numpy()
#
#                 tmp_eval_accuracy = flat_accuracy(logits, label_ids)
#                 eval_accuracy += tmp_eval_accuracy
#
#                 nb_eval_steps += 1
#
#             print(' Accuracy: {0:.2f}'.format(eval_accuracy/nb_eval_steps))
#             print(' Validation took: {:}'.format(format_time(time.time() - t0)))
#
#         print('')
#         print('Training completed')
#
#
#         # print loss
#         #%matplotlib inline
#
#         sns.set(style='darkgrid')
#         sns.set(font_scale=1.5)
#         plt.rcParams['figure.figsize'] = (12,6)
#
#         plt.plot(loss_values, 'b-o')
#
#         plt.title('Training loss')
#         plt.xlabel('Epoch')
#         plt.ylabel('Loss')
#
#         plt.show()
#
#
#     # test set evaluation
#     print('Predicting labels for {:,} test reports...'.format(len(test_inputs)))
#
#     model.eval()
#
#     predictions, true_labels, report_ids = [], [], []
#
#     t0 = time.time()
#
#     for (step, batch) in enumerate(test_dataloader):
#         if is_cuda_available:
#             batch = tuple(t.to(device) for t in batch)
#         else:
#             batch = tuple(t for t in batch)
#
#         if step % 100 == 0 and not step == 0:
#             elapsed = format_time(time.time() - t0)
#
#             print('Batch {:>5,} of {:>5,}. Elapsed {:}'.format(step, len(train_dataloader), elapsed))
#
#         b_input_ids, b_input_mask, b_labels, b_report_ids = batch
#
#         with torch.no_grad():
#             if model_name == 'bert':
#                 outputs = model(b_input_ids,
#                                 token_type_ids=None,
#                                 attention_mask=b_input_mask)
#             else:
#                 outputs = model(b_input_ids,
#                                 attention_mask=b_input_mask)
#
#         logits = outputs[0]
#
#         logits = logits.detach().cpu().numpy()
#         label_ids = b_labels.to('cpu').numpy()
#         batch_report_ids = b_report_ids.to('cpu').numpy()
#
#         predics = softmax(logits)
#
#         predictions.append(predics)
#         true_labels.append(label_ids)
#         report_ids.append(batch_report_ids)
#
#     print('Done')
#
#     # combine predictions across batches
#     predictions = np.concatenate(predictions, axis=0)
#     true_labels = np.concatenate(true_labels, axis=0)
#     report_ids = np.concatenate(report_ids, axis=0)
#
#     print(predictions[:10])
#     print(true_labels[:10])
#     print(report_ids[:10])
#
#     pred_labels = np.argmax(predictions, axis=1)
#     print(pred_labels[:10])
#
#     print(len(true_labels))
#     print(len(pred_labels))
#     print(len(predictions))
#     print(len(report_ids))
#
#     majority_predictions = compute_majority_voting(report_ids, pred_labels)
#     mean_predictions = compute_pooling(report_ids, predictions)
#
#     print(len(majority_predictions))
#     print(len(mean_predictions))
#     print(len(test_labels))
#
#     from sklearn.metrics import accuracy_score, f1_score
#
#     # with majority voting
#     print(accuracy_score(majority_predictions, test_labels))
#     print(f1_score(majority_predictions, test_labels))
#
#     # mean prediction
#     print(accuracy_score(mean_predictions, test_labels))
#     print(f1_score(mean_predictions, test_labels))
#
#     # just predictions
#     print(accuracy_score(predictions, true_labels))
#     print(f1_score(predictions, true_labels))
#
#     save_model(model, 'bert_10000')
#
#     #preprocess()
