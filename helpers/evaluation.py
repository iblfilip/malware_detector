import numpy as np
from sklearn.metrics import f1_score, accuracy_score
import logging

logger = logging.getLogger(__name__)


def compute_majority_voting(report_ids, predictions):
    if len(report_ids) != len(predictions):
        raise Exception('report_ids and predictions arrays must have same length')
        return

    new_labels = []

    for id in range(np.amax(report_ids) + 1):
        idxs = np.where(report_ids == id)[0]
        actual_preds = [predictions[idx] for idx in idxs]

        unique, counts = np.unique(actual_preds, return_counts=True)

        if len(counts) > 1:
            if counts[0] > counts[1]:
                new_labels.append(0)
            else:
                new_labels.append(1)
        else:
            new_labels.append(unique[0])

    return new_labels


def compute_pooling(report_ids, predictions):
    if len(report_ids) != len(predictions):
        raise Exception('report_ids and predictions arrays must have same length')
        return

    new_labels = []
    report_ids = np.array(report_ids)

    for id in range(np.amax(report_ids) + 1):
        idxs = np.where(report_ids == id)[0]
        actual_preds = [predictions[idx] for idx in idxs]
        mean_preds = np.mean(actual_preds, axis=0)
        pred = np.argmax(mean_preds)
        new_labels.append(pred)

    return new_labels


def print_results(preds, y):
    logger.info(' ------------------------')
    logger.info('| Accuracy score   {0:.3f} |'.format(accuracy_score(y, preds)))
    logger.info('| F1 score         {0:.3f} |'.format(f1_score(y, preds)))
    logger.info(' ------------------------')
