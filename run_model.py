from config.config import Config
from helpers.utils import load_dataset, split_dataset
from TransformerModel import TransformerModel
from classifiers.SVC import SVCModel
from classifiers.XGBoost import XGBoostModel
from TfidfModel import TfidfModel
from Doc2VecModel import Doc2VecModel
from Doc2VecCombinator import Doc2VecCombinator
import argparse
import logging

logger = logging.getLogger(__name__)


class ModelRunner:
    def __init__(self):
        self.do_training_emb = False
        self.do_training_cls = False
        # self.dataset_name = 'reports_apkinfo.manifest_apkinfo.dex_strings_apkinfo.interesting_strings_apkinfo.files'
        self.dataset_name = 'reports_'
        self.embedding = 'tfidf'
        self.classifier_name = 'xgboost'
        self.output_dir = 'save_models/'

        if args.train_emb:
            self.do_training_emb = True

        if args.train_cls:
            self.do_training_cls = True

        if args.dataset:
            self.dataset_name = args.dataset

        if args.embedding:
            self.embedding = args.embedding

        if args.classifier:
            self.classifier_name = args.classifier

        if args.output_dir:
            self.output_dir = args.output_dir

        if args.verbose:
            logging.basicConfig(level=logging.DEBUG)
        else:
            logging.basicConfig(level=logging.INFO)

        logger.info('Runner initialized with args')
        self.print_args()

    def print_args(self):
        logger.info(' ----------------------------')
        logger.info('| training embedding: ' + str(self.do_training_emb))
        logger.info('| training classifiers: ' + str(self.do_training_cls))
        logger.info('| dataset: ' + self.dataset_name)
        logger.info('| embedding: ' + self.embedding)
        logger.info('| classifier: ' + self.classifier_name)
        logger.info('| output dir: ' + self.output_dir)
        logger.info(' ----------------------------')

    def doc2vec_and_classify(self, train_reports, train_labels, validation_reports, validation_labels, test_reports,
                             test_labels):
        logger.info('--- DM model classification ---')
        dm_conf = Config({
            'do_training': self.do_training_emb,
            'model_name': 'model',
            'output_dir': self.output_dir,
            'dm': 1,
            'vector_size': 1000,
            'window': 10,
            'negative': 5,
            'hs': 0,
            'min_count': 50,
            'sample': 0,
            'alpha': 0.025,
            'compute_loss': True,
            'epochs': 10,
            'start_alpha': 0.025,
            'end_alpha': -0.00025,
        })
        dm_model = Doc2VecModel(dm_conf)

        if self.do_training_emb:
            dm_model.train(train_reports, train_labels, save_model=True)

        dm_train_vecs = dm_model.infer_vectors(train_reports, train_labels)
        dm_validation_vecs = dm_model.infer_vectors(validation_reports, validation_labels)
        dm_test_vecs = dm_model.infer_vectors(test_reports, test_labels)

        if self.classifier_name == 'svc':
            svc_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'svc_d2v_dm',
                'output_dir': self.output_dir,
                'C': 1.0,
                'loss': 'hinge',
                'gamma': 'auto',
                'kernel': 'linear',
                'random_value': 42
            })

            svc_model = SVCModel(svc_conf)

            if self.do_training_cls:
                svc_model.train(dm_train_vecs, train_labels, save_model=True)

            svc_model.predict(dm_train_vecs, train_labels, 'train')
            svc_model.predict(dm_validation_vecs, validation_labels, 'validation')
            svc_model.predict(dm_test_vecs, test_labels, 'test')

        elif self.classifier_name == 'xgboost':
            xgb_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'xgb_d2v_dm',
                'output_dir': self.output_dir,
                "n_estimators": [80],
                "eta": [0.01],
                "max_depth": [2],
                "learning_rate": [0.1],
                "min_child_weight": [5],
                "gamma": [0.3],
                'colsample_bytree': [0.3],
                'n_jobs': 4,
                'scoring': 'neg_log_loss',
                'cv': 3,
            })

            xgb_model = XGBoostModel(xgb_conf)

            if self.do_training_cls:
                xgb_model.train(dm_train_vecs, train_labels, save_model=True)

            xgb_model.predict(dm_train_vecs, train_labels, 'train')
            xgb_model.predict(dm_validation_vecs, validation_labels, 'validation')
            xgb_model.predict(dm_test_vecs, test_labels, 'test')

        logger.info('--- DBOW model classification ---')
        dbow_conf = Config({
            'do_training': self.do_training_emb,
            'model_name': 'model',
            'output_dir': self.output_dir,
            'dm': 0,
            'vector_size': 1000,
            'window': 10,
            'negative': 5,
            'hs': 0,
            'min_count': 50,
            'sample': 0,
            'alpha': 0.025,
            'compute_loss': True,
            'epochs': 10,
            'start_alpha': 0.025,
            'end_alpha': -0.00025,
        })

        dbow_model = Doc2VecModel(dbow_conf)

        if self.do_training_emb:
            dbow_model.train(train_reports, train_labels, save_model=True)

        dbow_train_vecs = dbow_model.infer_vectors(train_reports, train_labels)
        dbow_validation_vecs = dbow_model.infer_vectors(validation_reports, validation_labels)
        dbow_test_vecs = dbow_model.infer_vectors(test_reports, test_labels)

        if self.classifier_name == 'svc':
            svc_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'svc_d2v_dbow',
                'output_dir': self.output_dir,
                'C': 1.0,
                'loss': 'hinge',
                'gamma': 'auto',
                'kernel': 'linear',
                'random_value': 42
            })

            svc_model = SVCModel(svc_conf)

            if self.do_training_cls:
                svc_model.train(dbow_train_vecs, train_labels, save_model=True)

            svc_model.predict(dbow_train_vecs, train_labels)
            svc_model.predict(dbow_validation_vecs, validation_labels)
            svc_model.predict(dbow_test_vecs, test_labels)

        elif self.classifier_name == 'xgboost':
            xgb_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'xgb_d2v_dbow',
                'output_dir': self.output_dir,
                "n_estimators": [80],
                "eta": [0.01],
                "max_depth": [2],
                "learning_rate": [0.1],
                "min_child_weight": [5],
                "gamma": [0.3],
                'colsample_bytree': [0.3],
                'n_jobs': 4,
                'scoring': 'neg_log_loss',
                'cv': 3,
            })

            xgb_model = XGBoostModel(xgb_conf)

            if self.do_training_cls:
                xgb_model.train(dbow_train_vecs, train_labels, save_model=True)

            xgb_model.predict(dbow_train_vecs, train_labels, 'train')
            xgb_model.predict(dbow_validation_vecs, validation_labels, 'validation')
            xgb_model.predict(dbow_test_vecs, test_labels, 'test')

        logger.info('--- Combined model classification ---')
        combination = Doc2VecCombinator(
            dm_model.model_path,
            dbow_model.model_path
        )
        comb_train = combination.infer_vectors(train_reports, train_labels)
        comb_validation = combination.infer_vectors(validation_reports, validation_labels)
        comb_test = combination.infer_vectors(test_reports, test_labels)

        if self.classifier_name == 'svc':
            svc_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'svc_d2v_concat',
                'output_dir': self.output_dir,
                'C': 1.0,
                'loss': 'hinge',
                'gamma': 'auto',
                'kernel': 'linear',
                'random_value': 42
            })

            svc_model = SVCModel(svc_conf)

            if self.do_training_cls:
                svc_model.train(comb_train, train_labels, save_model=True)

            svc_model.predict(comb_train, train_labels, 'train')
            svc_model.predict(comb_validation, validation_labels, 'validation')
            svc_model.predict(comb_test, test_labels, 'test')

        elif self.classifier_name == 'xgboost':
            xgb_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'xgb_d2v_concat',
                'output_dir': self.output_dir,
                "n_estimators": [80],
                "eta": [0.01],
                "max_depth": [2],
                "learning_rate": [0.1],
                "min_child_weight": [5],
                "gamma": [0.3],
                'colsample_bytree': [0.3],
                'n_jobs': 4,
                'scoring': 'neg_log_loss',
                'cv': 3,
            })

            xgb_model = XGBoostModel(xgb_conf)

            if self.do_training_cls:
                xgb_model.train(comb_train, train_labels, save_model=True)

            xgb_model.predict(comb_train, train_labels, 'train')
            xgb_model.predict(comb_validation, validation_labels, 'validation')
            xgb_model.predict(comb_test, test_labels, 'test')

    def tfidf_and_classify(self, train_reports, train_labels, validation_reports, validation_labels, test_reports,
                           test_labels):
        tfidf_conf = Config({
            'do_training': self.do_training_emb,
            'model_name': 'tfidf_range_1_3_kbest_10000',
            'output_dir': self.output_dir,
            'ngram_range': (1, 3),
            'max_features': 100000,
            'k_best_features': 10000,
            'smooth_idf': True,
            'use_idf': True
        })

        tfidf_model = TfidfModel(tfidf_conf)

        if self.do_training_emb:
            tfidf_model.train(train_reports, train_labels, save_model=True)

        train_vectors = tfidf_model.transform(train_reports)
        validation_vectors = tfidf_model.transform(validation_reports)
        test_vectors = tfidf_model.transform(test_reports)

        if self.classifier_name == 'svc':
            svc_conf = Config({
                'do_training': self.do_training_cls,
                'model_name': 'svc_tfidf',
                'output_dir': self.output_dir,
                'C': 1.0,
                'loss': 'hinge',
                'gamma': 'auto',
                'kernel': 'linear',
                'random_value': 42
            })

            svc_model = SVCModel(svc_conf)

            if self.do_training_cls:
                svc_model.train(train_vectors, train_labels, save_model=True)

            svc_model.predict(train_vectors, train_labels, 'train')
            svc_model.predict(validation_vectors, validation_labels, 'validation')
            svc_model.predict(test_vectors, test_labels, 'test')


        elif self.classifier_name == 'xgboost':
            xgb_conf = Config({
                "do_training": self.do_training_cls,
                'model_name': 'xgb_tfidf',
                'output_dir': self.output_dir,
                "n_estimators": [80],
                "eta": [0.01],
                "max_depth": [2],
                "learning_rate": [0.1],
                "min_child_weight": [5],
                "gamma": [0.3],
                'colsample_bytree': [0.3],
                'n_jobs': 4,
                'scoring': 'neg_log_loss',
                'cv': 3,
            })

            xgb_model = XGBoostModel(xgb_conf)

            if self.do_training_cls:
                xgb_model.train(train_vectors, train_labels, save_model=True)

            xgb_model.predict(train_vectors, train_labels, 'train')
            xgb_model.predict(validation_vectors, validation_labels, 'validation')
            xgb_model.predict(test_vectors, test_labels, 'test')

    def transformer(self, train_reports, train_labels, validation_reports, validation_labels, test_reports,
                    test_labels):
        conf = Config({
            'do_training': self.do_training_emb,
            'model': 'bert',
            'model_name': 'bert_2000_batch8_lr2e-5_vers_2',
            'output_dir': self.output_dir,
            'tokens_threshold': 1500,
            'chunk_size': 500,
            'stride': 0,
            'batch_size': 8,
            'learning_rate': 2e-5,
            'eps': 1e-8,
            'n_epochs': 5,
            'random_value': 42,
        })

        model = TransformerModel(conf)

        if self.do_training_emb:
            model.train(train_reports, train_labels, validation_reports, validation_labels, save_model=True)

        model.predict(test_reports, test_labels)

    def run_model(self):
        to_string = True if self.embedding == 'tfidf' or self.embedding == 'doc2vec' else False

        reports, labels = load_dataset(self.dataset_name, to_string)
        train_reports, train_labels, validation_reports, validation_labels, test_reports, test_labels = split_dataset(
            reports,
            labels)

        if self.embedding == 'tfidf':
            self.tfidf_and_classify(train_reports, train_labels, validation_reports, validation_labels, test_reports,
                                    test_labels)

        elif self.embedding == 'doc2vec':
            self.doc2vec_and_classify(train_reports, train_labels, validation_reports, validation_labels, test_reports,
                                      test_labels)


        elif self.embedding == 'bert' or self.embedding == 'albert' or self.embedding == 'roberta' or self.embedding == 'distilbert' or self.embedding == 'flaubert':
            self.transformer(train_reports, train_labels, validation_reports, validation_labels, test_reports,
                             test_labels)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Running models on behavioural reports')
    parser.add_argument("-T", "--train_emb", help="mark if to do training of embedding", action="store_true")
    parser.add_argument("-T", "--train_cls", help="mark if to do training of classifier", action="store_true")
    parser.add_argument("-D", "--dataset", help="which dataset to use")
    parser.add_argument("-E", "--embedding", help="which embedding method to use -> tfidf | doc2vec | bert")
    parser.add_argument("-C", "--classifier",
                        help="which classifier to use for tfidf or doc2vec embedding -> svc | xgboost")
    parser.add_argument("-O", "--output_dir", help="Path to directory where models are stored")
    parser.add_argument("-v", "--verbose", help="use verbose logging level DEBUG", action="store_true")

    args = parser.parse_args()

    runner = ModelRunner()
    runner.run_model()
