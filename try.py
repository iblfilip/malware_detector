import numpy as np
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_extraction.text import CountVectorizer
from helpers.utils import load_dataset, clean_report
from downloader import load_reports
# from tfidf_embedding import tfidf_classify
from scipy.special import softmax
import json
import itertools


#             [0,1,2,3,1,3,0,4,5,6,1,2,0,4,5,5]
predictions = [1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,0]
true_labels = [1,1,0,1,1,1,0]

report_ids = [0,1,2,3,1,3,0,4,5,6,1,2,0,4,5,5]

pred_logits = [[-1.32, 3.2],
         [1.2, -2],
         [3.2, 1.4],
         [-3.3, 3.3]]

rep_ids_preds = [0,2,1,0]

report_ids_2 = [112,  13,  58,  28, 110,  90,  62,  22,  48,  15,  74,  63,  82,
        52,  36,  62,  93,  13, 101,  25,  40,  76,   6,  84, 111,  20,
        19,  50,  51,  37, 100,  75,  80,  91,   9,  79,  57,   7,  11,
        64,  51,  26, 107,  97,  12, 106,   6,  99,  30,  73,  68,   4,
        58,  72,   7,  60, 108,  33, 102,   3, 100,  33, 101,  96,  44,
        17,  19,  96,  80,  84, 111,   5,  94,  59,  55, 108,  27,  78,
        16,  98,  73,  18,  17,  70,  67,  12,  77,  39,  83, 106,   5,
       105,  89,  15,  69,  38,   3,  35,  34,  31,  66,  79,  50,  29,
       105,  23,  42,  34,  27,  54,  68,   0,  65,  60,  53,  40,  37,
        20,   0,  64,  95,  87,  14,  48,  29, 102,  32,  88,   2,  71,
        88,  86,  56,   9,  61,  74,  30,  85,  26,  95,  93,  49,  85,
        41, 104,  45, 109,  25,  10,  63,  43,  14, 104,  89,  32,  53,
        46,  47,  57, 103,  36,  92,  56,  21,  86,  94,  49,  78,  39,
        87,  92,  83,  22,   8,   2,  41,  81,   1,  31,  99,  54,  46,
        76,  70,  59,  81,  71,  72,  91,  61,  97,  23,  67,  18, 107,
        16, 112, 109,  52,  45,   1, 110,  47,   8,  35,  90,  75,  28,
        43,  77,  66,   4,  10,  24,  65,  24,  98,  21]

preds = [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,
       0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,
       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,
       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,
       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,
       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,
       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,
       1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,
       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,
       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]


report_ids_3= [121, 129, 145,  94,  33,  91,  64, 121]
predictions_3 = [1, 0, 0, 0, 0, 0, 0, 1]

report_ids = np.array(report_ids)
predictions = np.array(predictions)


def compute_majority_voting(report_ids, predictions):
    if len(report_ids) != len(predictions):
        raise Exception('report_ids and predictions arrays must have same length')
        return

    new_labels = []

    for id in range(np.amax(report_ids) + 1):
        idxs = np.where(report_ids == id)
        if len(idxs[0]) == 0:
            continue

        actual_preds = [predictions[idx] for idx in idxs]

        unique, counts = np.unique(actual_preds, return_counts=True)

        if len(counts) > 1:
            if counts[0] > counts[1]:
                new_labels.append(0)
            else:
                new_labels.append(1)
        else:
            new_labels.append(unique[0])

    return new_labels

#compute_majority_voting(report_ids, predictions)


def compute_pooling(report_ids, predictions):
    new_labels = []
    report_ids = np.array(report_ids)

    for id in range(np.amax(report_ids) + 1):
        idxs = np.where(report_ids == id)[0]
        actual_preds = [predictions[idx] for idx in idxs]
        mean_preds = np.mean(actual_preds, axis=0)
        pred = np.argmax(mean_preds)
        new_labels.append(pred)

    return new_labels


compute_pooling(rep_ids_preds, pred_logits)





def mutual_info():
    a = np.array([[1,1,2,1],[1,1,1,1]])
    b = np.array([1,2])

    res = mutual_info_classif(a, b)
    print('neco')


#mutual_info()


def calculate_mutual():
    reports, labels = load_dataset(make_clean=True)
    cv = CountVectorizer(max_df=0.95, min_df=2,
                         max_features=10000)
    X_vec = cv.fit_transform(reports)
    res = dict(zip(cv.get_feature_names(), mutual_info_classif(X_vec, labels)))
    # print(res[:10])
    srt = dict(sorted(res.items(), key=lambda x: x[1], reverse=True)[:20])

    print('done')



    # mit list vsech features
    # kombinovat vzdy 2 features
    # nahrat report s 2 vybranyma features
    # vypocitat


def cal_mut(calc_tuples=False, measure_first_100=False):
    # removed apkinfo
    with open('report.json') as file:
        data = json.load(file)
    first_order_keys = data.keys()

    keys = []

    for first_key in first_order_keys:
        if type(data[first_key]) is dict and first_key == 'apkinfo':
            second_order_keys = data[first_key].keys()
            keys.extend([first_key + '.' + second_key for second_key in second_order_keys])
        else:
            keys.append(first_key)

    first_order_keys = list(first_order_keys)
    second_order_keys = list(second_order_keys)

    first_order_keys.remove('info')
    first_order_keys.remove('virustotal')
    first_order_keys.remove('apkinfo')

    sec = ['apkinfo.' + key for key in second_order_keys]

    sec.extend(first_order_keys)

    first_order_keys = sec


    properties = ['info', 'network', 'procmemory', 'droidmon', 'virustotal', 'signatures', 'static', 'behavior', 'target', 'debug',
                  'strings', 'dropped']
    apkinfo_props = ['files', 'dex_strings', 'hidden_payload',  'files_flaged', 'interesting_strings', 'manifest', 'static_method_calls', 'icon']



    props_list =  []
    combinations = list(itertools.combinations(first_order_keys, 2))

    if calc_tuples:
        for (attr_1, attr_2) in combinations:
            calc_mut_info_on_report(attr_1, attr_2, measure_first_100)
    else:
        for attr_1 in first_order_keys:
            calc_mut_info_on_report(attr_1, None, measure_first_100)



def calc_mut_info_on_report(attr_1=None, attr_2=None, measure_first_100=False):
    reports = load_reports(attr_1)
    reports_text = [' '.join(clean_report(report)) for report in reports]
    labels = [0 if report['label'] == 'beningware' else 1 for report in reports]
    print('---')

    # if 'network' in attr_1:
    #     print('bla')
    # if 'apkinfo' in attr_1:
    #     print('neco')

    cv = CountVectorizer(
        # max_df=0.95,
        # min_df=2,
        max_features=10000)
    X_vec = cv.fit_transform(reports_text)
    res = dict(zip(cv.get_feature_names(), mutual_info_classif(X_vec, labels)))

    srt = dict(sorted(res.items(), key=lambda x: x[1], reverse=True)[:100])

    print(attr_1, attr_2)

    if measure_first_100:
        cummulative_gain = 0
        for name, val in srt.items():
            cummulative_gain += val

        mean = cummulative_gain / 100

    else:
        sum = 0
        for key, val in res.items():
            sum += val
        n_items = len(res.items())
        mean = sum / n_items

    print('>>>>>> {}'.format(mean))


def softmax_try():
    logits = [-1.23, -1.65]
    res = softmax(logits)
    print('done')

#softmax_try()

#cal_mut(calc_tuples=False, measure_first_100=True)






